{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NpG121r7rr_K"
   },
   "outputs": [],
   "source": [
    "using_colab = False\n",
    "if using_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-XN3eeyirquR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "mean = np.array([0.4848, 0.5121, 0.5102]).reshape(1, 1, 3)\n",
    "std = np.array([0.2404, 0.2356, 0.2608]).reshape(1, 1, 3)\n",
    "\n",
    "def natural_sort_key(filename):\n",
    "    return [int(s) if s.isdigit() else s for s in re.split(\"(\\d+)\", filename)]\n",
    "\n",
    "\n",
    "def addPadding(srcShapeTensor, tensor_whose_shape_isTobechanged):\n",
    "\n",
    "    if(srcShapeTensor.shape != tensor_whose_shape_isTobechanged.shape):\n",
    "        target = torch.zeros(srcShapeTensor.shape)\n",
    "        target[:, :, :tensor_whose_shape_isTobechanged.shape[2],\n",
    "               :tensor_whose_shape_isTobechanged.shape[3]] = tensor_whose_shape_isTobechanged\n",
    "        return target.to(device)\n",
    "    return tensor_whose_shape_isTobechanged.to(device)\n",
    "\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir=None, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_filenames = sorted(os.listdir(image_dir), key=natural_sort_key)\n",
    "\n",
    "        if mask_dir is None:\n",
    "            self.mask_dir = None\n",
    "        else:\n",
    "            self.mask_dir = mask_dir\n",
    "            self.mask_filenames = sorted(os.listdir(mask_dir), key=natural_sort_key)\n",
    "            if self.image_filenames != self.mask_filenames:\n",
    "                raise ValueError(\"Image and mask filenames do not match!\")\n",
    "\n",
    "        self.preprocess = A.Compose([\n",
    "            A.Resize(256, 256),\n",
    "            ToTensorV2()\n",
    "            ])\n",
    "        self.transform = transform\n",
    "        self.color_transform = T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.05)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.image_filenames[idx])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = np.array(image) / 255\n",
    "        image = ((image - mean) / std)\n",
    "        image = image.astype(np.float32)\n",
    "\n",
    "        if self.mask_dir is None:\n",
    "            image = self.preprocess(image=image)['image']\n",
    "            return image\n",
    "        else:\n",
    "            mask_path = os.path.join(self.mask_dir, self.mask_filenames[idx])\n",
    "            mask = Image.open(mask_path).convert(\"L\")\n",
    "            mask = np.array(mask).astype(np.float32)\n",
    "            mask = np.where(mask > 0, 0.999999, 0)\n",
    "\n",
    "            if self.transform:\n",
    "                t = self.transform(image=image, mask=mask)\n",
    "                image = t['image']\n",
    "                mask = t['mask']\n",
    "            else:\n",
    "                t = self.preprocess(image=image, mask=mask)\n",
    "                image = t['image']\n",
    "                mask = t['mask']\n",
    "            return image, mask\n",
    "\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, do_dropout=False, do_attention=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.do_dropout = do_dropout\n",
    "        self.do_attention = do_attention\n",
    "\n",
    "        self.enc1 = self.double_conv(3, 64)\n",
    "        self.enc2 = self.double_conv(64, 128)\n",
    "        self.enc3 = self.double_conv(128, 256)\n",
    "        self.enc4 = self.double_conv(256, 512)\n",
    "        self.enc5 = self.double_conv(512, 1024)\n",
    "\n",
    "        self.up5 = self.up_trans(1024, 512)\n",
    "        self.att5 = AttentionBlock(F_g=512, F_l=512, F_int=256)\n",
    "        self.dec5 = self.double_conv(1024, 512)\n",
    "\n",
    "        self.up4 = self.up_trans(512, 256)\n",
    "        self.att4 = AttentionBlock(F_g=256, F_l=256, F_int=128)\n",
    "        self.dec4 = self.double_conv(512, 256)\n",
    "\n",
    "        self.up3 = self.up_trans(256, 128)\n",
    "\n",
    "        self.dec3 = self.double_conv(256, 128)\n",
    "        self.att3 = AttentionBlock(F_g=128, F_l=128, F_int=64)\n",
    "        self.up2 = self.up_trans(128, 64)\n",
    "\n",
    "        self.dec2 = self.double_conv(128, 64)\n",
    "        self.att2 = AttentionBlock(F_g=64, F_l=64, F_int=32)\n",
    "        self.final_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def double_conv(self, in_channels, out_channels):\n",
    "        if self.do_dropout:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.Dropout2d(0.2),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.Dropout2d(0.2),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "    def up_trans(self, in_channels, out_channels):\n",
    "        return nn.ConvTranspose2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size = 2,\n",
    "            stride = 2\n",
    "        )\n",
    "\n",
    "    def crop_and_concat(self, upsampled, bypass):\n",
    "        return torch.cat((upsampled, bypass), dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(nn.MaxPool2d(2)(enc1))\n",
    "        enc3 = self.enc3(nn.MaxPool2d(2)(enc2))\n",
    "        enc4 = self.enc4(nn.MaxPool2d(2)(enc3))\n",
    "        enc5 = self.enc5(nn.MaxPool2d(2)(enc4))\n",
    "\n",
    "        x = self.up5(enc5)\n",
    "        x = addPadding(enc4, x)\n",
    "        if self.do_attention:\n",
    "            x = self.att5(x, enc4)\n",
    "        x = self.dec5(self.crop_and_concat(x, enc4))\n",
    "\n",
    "        x = self.up4(x)\n",
    "        x = addPadding(enc3, x)\n",
    "        if self.do_attention:\n",
    "            x = self.att4(x, enc3)\n",
    "        x = self.dec4(self.crop_and_concat(x, enc3))\n",
    "\n",
    "        x = self.up3(x)\n",
    "        x = addPadding(enc2, x)\n",
    "        if self.do_attention:\n",
    "            x = self.att3(x, enc2)\n",
    "        x = self.dec3(self.crop_and_concat(x, enc2))\n",
    "\n",
    "        x = self.up2(x)\n",
    "        x = addPadding(enc1, x)\n",
    "        if self.do_attention:\n",
    "            x = self.att2(x, enc1)\n",
    "        x = self.dec2(self.crop_and_concat(x, enc1))\n",
    "\n",
    "        output = torch.sigmoid(self.final_conv(x))\n",
    "        return output\n",
    "\n",
    "\n",
    "def calculate_iou(output, target, threshold=0.5):\n",
    "    output = output > threshold\n",
    "    target = target > 0\n",
    "\n",
    "    output_flat = output.view(-1)\n",
    "    target_flat = target.view(-1)\n",
    "\n",
    "    intersection = (output_flat & target_flat).sum().float()\n",
    "    union = (output_flat | target_flat).sum().float()\n",
    "    if union == 0:\n",
    "        print(\"UNION SHOULD NOT BE ZERO, THERE MUST BE SOME MISTAKE\")\n",
    "        return 1\n",
    "\n",
    "    iou = intersection / union\n",
    "    return iou.item()\n",
    "\n",
    "\n",
    "def tensor_to_required_image(image, input_path, input_index, have_input_concated=True):\n",
    "    image = image.squeeze().cpu().numpy() > 0.5\n",
    "\n",
    "    input_image = Image.open(f\"{input_path}/{input_index}.png\")\n",
    "    input_shape = input_image.size\n",
    "    if have_input_concated:\n",
    "        input_shape = (input_shape[0] * 2, input_shape[1])\n",
    "    else:\n",
    "        input_shape = (input_shape[0], input_shape[1])\n",
    "\n",
    "    image = Image.fromarray((image * 255).astype(np.uint8))\n",
    "    image = image.resize(input_shape)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Fg7KaBV_rquW"
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.ElasticTransform(alpha=120, sigma=120 * 0.05, p=0.3),\n",
    "    A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=0.3),\n",
    "    # A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    # A.VerticalFlip(p=0.2),\n",
    "    # A.GaussianBlur(blur_limit=(3, 5), p=0.3),\n",
    "    A.GaussNoise(var_limit=(0.001, 0.01), p=0.2),\n",
    "    # A.ChannelShuffle(p=0.1),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "if using_colab:\n",
    "    directory_path = \"/content/drive/MyDrive/WaterSegementation/training_dataset\"\n",
    "else:\n",
    "    directory_path = \"./training_dataset\"\n",
    "train_dataset = SegmentationDataset(f\"{directory_path}/image\", f\"{directory_path}/mask\", transform=train_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "pretend_train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - pretend_train_size\n",
    "_, val_subset = random_split(train_dataset, [pretend_train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "val_dataloader = DataLoader(val_subset, batch_size=8, shuffle=False)\n",
    "\n",
    "if using_colab:\n",
    "    directory_path = \"/content/drive/MyDrive/WaterSegementation/testing_dataset\"\n",
    "else:\n",
    "    directory_path = \"./testing_dataset\"\n",
    "test_dataset = SegmentationDataset(f\"{directory_path}/image\")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = UNet().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = [\"train\", \"valid\"]\n",
    "data_loader = {\"train\": train_dataloader, \"valid\": val_dataloader}\n",
    "top_n = 5\n",
    "top_mean_ious = [0] * top_n\n",
    "top_epochs = [0] * top_n\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cR5ARwgrquX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Time: 6.68 Training Loss: 7.2139, Validation Mean IoU: 0.0007\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for phase in phases:\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            train_iou_scores = []\n",
    "        elif phase == \"valid\":\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_iou_scores = []\n",
    "\n",
    "        for images, masks in data_loader[phase]:\n",
    "            images, masks = images.to(device), masks.to(device).unsqueeze(1)\n",
    "\n",
    "            if phase == \"train\":\n",
    "                outputs = model(images)\n",
    "\n",
    "                loss = criterion(outputs, masks)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                # iou = calculate_iou(outputs, masks)\n",
    "                # train_iou_scores.append(iou)\n",
    "            elif phase == \"valid\":\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(images)\n",
    "\n",
    "                    # loss = criterion(outputs, masks)\n",
    "\n",
    "                    # val_loss += loss.item()\n",
    "\n",
    "                    iou = calculate_iou(outputs, masks)\n",
    "                    val_iou_scores.append(iou)\n",
    "\n",
    "    end_time = time.time()\n",
    "    # train_mean_iou = sum(train_iou_scores) / len(train_iou_scores)\n",
    "    val_mean_iou = sum(val_iou_scores) / len(val_iou_scores)\n",
    "    # print(f\"Epoch {epoch+1}/{num_epochs}, Time: {end_time - start_time:.2f} Training Loss: {train_loss:.4f}, Training Mean IoU: {train_mean_iou:.4f}, Validation Loss: {val_loss:.4f}, Validation Mean IoU: {val_mean_iou:.4f}\")\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Time: {end_time - start_time:.2f} Training Loss: {train_loss:.4f}, Validation Mean IoU: {val_mean_iou:.4f}\")\n",
    "\n",
    "    for i in range(5):\n",
    "        if val_mean_iou > top_mean_ious[i]:\n",
    "            top_mean_ious[i] = val_mean_iou\n",
    "            top_epochs[i] = epoch\n",
    "            torch.save(model.state_dict(), f'top_{i + 1}.pth')\n",
    "            break\n",
    "\n",
    "print(\"Training Complete!\")\n",
    "print(f\"Top Mean IoUs: {top_mean_ious}, at epochs {top_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkYVSAuyrquY"
   },
   "outputs": [],
   "source": [
    "ensemble_outputs_list = []\n",
    "ensemble_confident = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "\n",
    "for n in range(top_n):\n",
    "    model.load_state_dict(torch.load(f'top_{n + 1}.pth', weights_only=True))\n",
    "    model.eval()\n",
    "    output_dir = \"./testing_dataset\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, images in enumerate(tqdm.tqdm(test_dataloader)):\n",
    "            images = images.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            if len(ensemble_outputs_list) == idx:\n",
    "                ensemble_outputs_list.append(outputs * ensemble_confident[n])\n",
    "            else:\n",
    "                ensemble_outputs_list[idx] += outputs * ensemble_confident[n]\n",
    "\n",
    "for idx, images in enumerate(test_dataloader):\n",
    "    outputs = ensemble_outputs_list[idx]\n",
    "\n",
    "    output_image_path = os.path.join(f\"{output_dir}/output\", f\"{idx + 1}.png\")\n",
    "    output_image = tensor_to_required_image(outputs, f\"{directory_path}/image\", idx + 1, have_input_concated=False)\n",
    "    output_image.save(output_image_path)\n",
    "\n",
    "    print(f\"Saved output for image {idx + 1}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_outputs_list = []\n",
    "ensemble_confident = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "alpha = 0.1\n",
    "\n",
    "test_transforms = [\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    T.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))\n",
    "    ]\n",
    "\n",
    "for n in range(top_n):\n",
    "    model.load_state_dict(torch.load(f'top_{n + 1}.pth', weights_only=True))\n",
    "    model.eval()\n",
    "    output_dir = \"./testing_dataset\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, images in enumerate(tqdm.tqdm(test_dataloader)):\n",
    "            images = images.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            for test_transform in test_transforms:\n",
    "                images = test_transform(images)\n",
    "                outputs += model(images)\n",
    "            \n",
    "            outputs = outputs / (len(test_transforms) + 1)\n",
    "\n",
    "            if len(ensemble_outputs_list) == idx:\n",
    "                ensemble_outputs_list.append(outputs * ensemble_confident[n])\n",
    "            else:\n",
    "                ensemble_outputs_list[idx] += outputs * ensemble_confident[n]\n",
    "\n",
    "for idx, images in enumerate(test_dataloader):\n",
    "    outputs = ensemble_outputs_list[idx]\n",
    "\n",
    "    previous_output_image_path = os.path.join(f\"{output_dir}/output\", f\"{idx + 1}.png\")\n",
    "\n",
    "    saved_image = Image.open(previous_output_image_path).convert(\"L\")\n",
    "    saved_image_array = np.array(saved_image) / 255\n",
    "\n",
    "    saved_water_to_image_ratio = np.sum(saved_image_array) / saved_image_array.size\n",
    "    TTA_water_to_image_ratio = np.sum(np.array(outputs.cpu()) > 0.5) / np.array(outputs.cpu()).size\n",
    "\n",
    "    if saved_water_to_image_ratio < alpha and TTA_water_to_image_ratio > saved_water_to_image_ratio:\n",
    "        print(f\"Replace output for image {idx + 1}. Original ratio:{saved_water_to_image_ratio:.4f} new ratio: {TTA_water_to_image_ratio:.4f}\")\n",
    "        \n",
    "        output_image_path = os.path.join(f\"{output_dir}/output\", f\"{idx + 1}.png\")\n",
    "        output_image = tensor_to_required_image(outputs, f\"{directory_path}/image\", idx + 1, have_input_concated=False)\n",
    "        output_image.save(output_image_path)\n",
    "\n",
    "    print(f\"Image {idx + 1}. Original ratio:{saved_water_to_image_ratio:.4f} new ratio: {TTA_water_to_image_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcPXHLN3NIAh"
   },
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "    directory_path = \"/content/drive/MyDrive/WaterSegementation/testing_dataset\"\n",
    "else:\n",
    "    directory_path = \"./testing_dataset\"\n",
    "test_dataset = SegmentationDataset(f\"{directory_path}/image\", f\"{directory_path}/mask\")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MoCbaBlDNvNo"
   },
   "outputs": [],
   "source": [
    "test_iou_scores = []\n",
    "model.load_state_dict(torch.load(f'top_{1}.pth', weights_only=True))\n",
    "model.eval()\n",
    "output_dir = \"./output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (images, masks) in enumerate(test_dataloader):\n",
    "        images, masks = images.to(device), masks.to(device).unsqueeze(1)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        iou = calculate_iou(outputs, masks)\n",
    "        test_iou_scores.append(iou)\n",
    "\n",
    "        output_and_mask_image_path = os.path.join(output_dir, f\"output_{idx + 1}.png\")\n",
    "        output_and_mask = torch.cat((masks, outputs), dim=3)\n",
    "        output_and_mask_image = tensor_to_required_image(output_and_mask, f\"{directory_path}/mask\", idx + 1)\n",
    "        output_and_mask_image.save(output_and_mask_image_path)\n",
    "\n",
    "        output_image_path = os.path.join(output_dir, f\"{idx + 1}.png\")\n",
    "        output_image = tensor_to_required_image(outputs, f\"{directory_path}/mask\", idx + 1)\n",
    "        output_image.save(output_image_path)\n",
    "\n",
    "        print(f\"Saved output and mask for image {idx + 1}. IoU: {iou:.4f}\")\n",
    "\n",
    "mean_iou = sum(test_iou_scores) / len(test_iou_scores)\n",
    "print(f\"Mean IoU: {mean_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-1l_3koNWdT"
   },
   "outputs": [],
   "source": [
    "test_iou_scores = []\n",
    "ensemble_outputs_list = []\n",
    "ensemble_confident = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "\n",
    "test_transforms = [\n",
    "    # T.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    # T.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))\n",
    "    ]\n",
    "\n",
    "for n in range(top_n):\n",
    "    model.load_state_dict(torch.load(f'top_{n + 1}.pth', weights_only=True))\n",
    "    model.eval()\n",
    "    output_dir = \"./output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (images, masks) in enumerate(tqdm.tqdm(test_dataloader)):\n",
    "            images, masks = images.to(device), masks.to(device).unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            for test_transform in test_transforms:\n",
    "                images = test_transform(images)\n",
    "                outputs += model(images)\n",
    "            \n",
    "            outputs = outputs / (len(test_transforms) + 1)\n",
    "\n",
    "            if len(ensemble_outputs_list) == idx:\n",
    "                ensemble_outputs_list.append(outputs * ensemble_confident[n])\n",
    "            else:\n",
    "                ensemble_outputs_list[idx] += outputs * ensemble_confident[n]\n",
    "\n",
    "for idx, (images, masks) in enumerate(test_dataloader):\n",
    "    masks = masks.to(device).unsqueeze(1)\n",
    "    outputs = ensemble_outputs_list[idx]\n",
    "\n",
    "    iou = calculate_iou(outputs, masks)\n",
    "    test_iou_scores.append(iou)\n",
    "\n",
    "    output_and_mask_image_path = os.path.join(output_dir, f\"output_{idx + 1}.png\")\n",
    "    output_and_mask = torch.cat((masks, outputs), dim=3)\n",
    "    output_and_mask_image = tensor_to_required_image(output_and_mask, f\"{directory_path}/mask\", idx + 1)\n",
    "    output_and_mask_image.save(output_and_mask_image_path)\n",
    "    \n",
    "    output_image_path = os.path.join(output_dir, f\"{idx + 1}.png\")\n",
    "    output_image = tensor_to_required_image(outputs, f\"{directory_path}/mask\", idx + 1, have_input_concated=False)\n",
    "    output_image.save(output_image_path)\n",
    "\n",
    "    print(f\"Saved output and mask for image {idx + 1}. IoU: {iou:.4f}\")\n",
    "\n",
    "mean_iou = sum(test_iou_scores) / len(test_iou_scores)\n",
    "print(f\"Mean IoU: {mean_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_outputs_list = []\n",
    "ensemble_confident = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "alpha = 0.1\n",
    "\n",
    "test_transforms = [\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    T.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))\n",
    "    ]\n",
    "\n",
    "for n in range(top_n):\n",
    "    model.load_state_dict(torch.load(f'top_{n + 1}.pth', weights_only=True))\n",
    "    model.eval()\n",
    "    output_dir = \"./output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (images, masks) in enumerate(tqdm.tqdm(test_dataloader)):\n",
    "            images = images.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            for test_transform in test_transforms:\n",
    "                images = test_transform(images)\n",
    "                outputs += model(images)\n",
    "            \n",
    "            outputs = outputs / (len(test_transforms) + 1)\n",
    "\n",
    "            if len(ensemble_outputs_list) == idx:\n",
    "                ensemble_outputs_list.append(outputs * ensemble_confident[n])\n",
    "            else:\n",
    "                ensemble_outputs_list[idx] += outputs * ensemble_confident[n]\n",
    "\n",
    "for idx, (images, masks) in enumerate(test_dataloader):\n",
    "    masks = masks.to(device).unsqueeze(1)\n",
    "    outputs = ensemble_outputs_list[idx]\n",
    "\n",
    "    previous_output_image_path = os.path.join(f\"{output_dir}\", f\"{idx + 1}.png\")\n",
    "\n",
    "    saved_image = Image.open(previous_output_image_path).convert(\"L\")\n",
    "    saved_image_array = np.array(saved_image) / 255\n",
    "\n",
    "    saved_water_to_image_ratio = np.sum(saved_image_array) / saved_image_array.size\n",
    "    TTA_water_to_image_ratio = np.sum(np.array(outputs.cpu()) > 0.5) / np.array(outputs.cpu()).size\n",
    "\n",
    "    if saved_water_to_image_ratio < alpha and TTA_water_to_image_ratio > saved_water_to_image_ratio:\n",
    "        iou = calculate_iou(outputs, masks)\n",
    "        print(f\"Replace output for image {idx + 1}. Original IoU:{test_iou_scores[idx]:.4f} IoU: {iou:.4f}\")\n",
    "        test_iou_scores[idx] = iou\n",
    "        \n",
    "        output_image_path = os.path.join(f\"{output_dir}\", f\"{idx + 1}.png\")\n",
    "        output_image = tensor_to_required_image(outputs, f\"{directory_path}/image\", idx + 1, have_input_concated=False)\n",
    "        output_image.save(output_image_path)\n",
    "        \n",
    "        output_and_mask_image_path = os.path.join(output_dir, f\"output_{idx + 1}.png\")\n",
    "        output_and_mask = torch.cat((masks, outputs), dim=3)\n",
    "        output_and_mask_image = tensor_to_required_image(output_and_mask, f\"{directory_path}/mask\", idx + 1)\n",
    "        output_and_mask_image.save(output_and_mask_image_path)\n",
    "\n",
    "    print(f\"Image {idx + 1}. IoU: {test_iou_scores[idx]:.4f}\")\n",
    "\n",
    "mean_iou = sum(test_iou_scores) / len(test_iou_scores)\n",
    "print(f\"Mean IoU: {mean_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
