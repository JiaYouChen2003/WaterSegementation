{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TRzd6WqjR_m",
        "outputId": "66eb2919-515b-4c7e-bdc1-86f59c54b455"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gglXighqizg0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def natural_sort_key(filename):\n",
        "    return [int(s) if s.isdigit() else s for s in re.split(\"(\\d+)\", filename)]\n",
        "\n",
        "def addPadding(srcShapeTensor, tensor_whose_shape_isTobechanged):\n",
        "\n",
        "    if(srcShapeTensor.shape != tensor_whose_shape_isTobechanged.shape):\n",
        "        target = torch.zeros(srcShapeTensor.shape)\n",
        "        target[:, :, :tensor_whose_shape_isTobechanged.shape[2],\n",
        "               :tensor_whose_shape_isTobechanged.shape[3]] = tensor_whose_shape_isTobechanged\n",
        "        return target.to(device)\n",
        "    return tensor_whose_shape_isTobechanged.to(device)\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # 使用 Sigmoid 將輸出壓縮到 [0, 1]\n",
        "        # inputs = torch.sigmoid(inputs)\n",
        "\n",
        "        # 展平\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        # 計算交集和\n",
        "        intersection = (inputs * targets).sum()\n",
        "        dice_coefficient = (2. * intersection + self.smooth) / (inputs.sum() + targets.sum() + self.smooth)\n",
        "\n",
        "        # 計算 Dice Loss\n",
        "        dice_loss = 1 - dice_coefficient\n",
        "        return dice_loss\n",
        "\n",
        "class CombinedLoss(nn.Module):\n",
        "    def __init__(self, weight_dice=0.5, weight_ce=0.5, smooth=1e-6):\n",
        "        super(CombinedLoss, self).__init__()\n",
        "        self.dice_loss = DiceLoss(smooth=smooth)\n",
        "        self.cross_entropy = nn.BCEWithLogitsLoss()\n",
        "        self.weight_dice = weight_dice\n",
        "        self.weight_ce = weight_ce\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        dice_loss = self.dice_loss(inputs, targets)\n",
        "        ce_loss = self.cross_entropy(inputs, targets)\n",
        "        combined_loss = self.weight_dice * dice_loss + self.weight_ce * ce_loss\n",
        "        return combined_loss\n",
        "\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.image_filenames = sorted(os.listdir(image_dir), key=natural_sort_key)\n",
        "        self.mask_filenames = sorted(os.listdir(mask_dir), key=natural_sort_key)\n",
        "\n",
        "        if self.image_filenames != self.mask_filenames:\n",
        "            raise ValueError(\"Image and mask filenames do not match!\")\n",
        "\n",
        "        self.preprocess = transforms.Compose([\n",
        "            # transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        self.transform = transform\n",
        "        self.color_transform = transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.05)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_dir, self.image_filenames[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.mask_filenames[idx])\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        image = np.array(image).astype(np.float32)\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "        mask = np.array(mask)\n",
        "        mask = np.where(mask > 0, 0.999999, 0).astype(np.float32)\n",
        "\n",
        "        if self.transform:\n",
        "          t = self.transform(image=image, mask=mask)\n",
        "          image = t['image']\n",
        "          mask = t['mask']\n",
        "\n",
        "        # image = self.preprocess(image)\n",
        "        # mask = self.preprocess(mask)\n",
        "\n",
        "        # if self.transform:\n",
        "        #     image = self.color_transform(image)\n",
        "\n",
        "        #     image_and_mask = torch.cat((image, mask))\n",
        "        #     image_and_mask = self.transform(torch.cat((image, mask), dim=0))\n",
        "        #     image = image_and_mask[0:3]\n",
        "        #     mask = image_and_mask[3].unsqueeze(0)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, F_g, F_l, F_int):\n",
        "        super(AttentionBlock, self).__init__()\n",
        "        self.W_g = nn.Sequential(\n",
        "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "        self.W_x = nn.Sequential(\n",
        "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        psi = self.relu(g1 + x1)\n",
        "        psi = self.psi(psi)\n",
        "        return x * psi\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        self.enc1 = self.double_conv(3, 8)\n",
        "        self.enc2 = self.double_conv(8, 8)\n",
        "        self.enc3 = self.double_conv(8, 8)\n",
        "        self.enc4 = self.double_conv(8, 8)\n",
        "        self.enc5 = self.double_conv(8, 8)\n",
        "\n",
        "        self.up5 = self.up_trans(8, 8)\n",
        "        self.att5 = AttentionBlock(F_g=8, F_l=8, F_int=4)\n",
        "        self.dec5 = self.double_conv(16, 8)\n",
        "\n",
        "        self.up4 = self.up_trans(8, 8)\n",
        "        self.att4 = AttentionBlock(F_g=8, F_l=8, F_int=4)\n",
        "        self.dec4 = self.double_conv(16, 8)\n",
        "\n",
        "        self.up3 = self.up_trans(8, 8)\n",
        "        self.att3 = AttentionBlock(F_g=8, F_l=8, F_int=4)\n",
        "        self.dec3 = self.double_conv(16, 8)\n",
        "\n",
        "        self.up2 = self.up_trans(8, 8)\n",
        "        self.att2 = AttentionBlock(F_g=8, F_l=8, F_int=4)\n",
        "        self.dec2 = self.double_conv(16, 8)\n",
        "\n",
        "        self.final_conv = nn.Conv2d(8, 1, kernel_size=1)\n",
        "\n",
        "    def double_conv(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.3),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.3)\n",
        "        )\n",
        "\n",
        "    def up_trans(self, in_channels, out_channels):\n",
        "        return nn.ConvTranspose2d(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size = 2,\n",
        "            stride = 2\n",
        "        )\n",
        "\n",
        "    def crop_and_concat(self, upsampled, bypass):\n",
        "        return torch.cat((upsampled, bypass), dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(nn.MaxPool2d(2)(enc1))\n",
        "        enc3 = self.enc3(nn.MaxPool2d(2)(enc2))\n",
        "        enc4 = self.enc4(nn.MaxPool2d(2)(enc3))\n",
        "        enc5 = self.enc5(nn.MaxPool2d(2)(enc4))\n",
        "\n",
        "        x = self.up5(enc5)\n",
        "        x = addPadding(enc4, x)\n",
        "        x = self.att5(x, enc4)\n",
        "        x = self.dec5(self.crop_and_concat(x, enc4))\n",
        "\n",
        "        x = self.up4(x)\n",
        "        x = addPadding(enc3, x)\n",
        "        x = self.att4(x, enc3)\n",
        "        x = self.dec4(self.crop_and_concat(x, enc3))\n",
        "\n",
        "        x = self.up3(x)\n",
        "        x = addPadding(enc2, x)\n",
        "        x = self.att3(x, enc2)\n",
        "        x = self.dec3(self.crop_and_concat(x, enc2))\n",
        "\n",
        "        x = self.up2(enc2)\n",
        "        x = addPadding(enc1, x)\n",
        "        x = self.att2(x, enc1)\n",
        "        x = self.dec2(self.crop_and_concat(x, enc1))\n",
        "\n",
        "        output = torch.sigmoid(self.final_conv(x))\n",
        "        return output\n",
        "\n",
        "\n",
        "def calculate_iou(output, target, threshold=0.5):\n",
        "    output = output > threshold\n",
        "    target = target > 0\n",
        "\n",
        "    output_flat = output.view(-1)\n",
        "    target_flat = target.view(-1)\n",
        "\n",
        "    intersection = (output_flat & target_flat).sum().float()\n",
        "    union = (output_flat | target_flat).sum().float()\n",
        "    if union == 0:\n",
        "        print(\"UNION SHOULD NOT BE ZERO, THERE MUST BE SOME MISTAKE\")\n",
        "        return 1\n",
        "\n",
        "    iou = intersection / union\n",
        "    return iou.item()\n",
        "\n",
        "\n",
        "def tensor_to_required_image(image, input_path, input_index):\n",
        "    image = image > 0.5\n",
        "\n",
        "    ref_image = Image.open(f\"{input_path}/{input_index}.png\")\n",
        "    ref_shape = ref_image.size\n",
        "    ref_shape = (ref_shape[0] * 2, ref_shape[1])\n",
        "\n",
        "    image = Image.fromarray((image * 255).astype(np.uint8))\n",
        "    image = image.resize(ref_shape)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JItpnrX4i0b4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf1Z-lRvizg2",
        "outputId": "88839453-ba8d-413d-8562-1c82a9c66492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-dfa9eb18e59e>:9: UserWarning: Argument 'alpha_affine' is not valid and will be ignored.\n",
            "  A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.3),\n"
          ]
        }
      ],
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "transform = A.Compose([\n",
        "    A.Resize(512, 512),\n",
        "    A.RandomSizedCrop(min_max_height=(128, 512), height=512, width=512, p=0.5),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "    # A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
        "    A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.3),\n",
        "    A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=0.3),\n",
        "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.2),\n",
        "    A.GaussianBlur(blur_limit=(3, 5), p=0.3),\n",
        "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
        "    A.ChannelShuffle(p=0.1),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# train_transform = transforms.Compose([\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.RandomRotation(30),\n",
        "#     transforms.RandomResizedCrop(256, scale=(0.3, 1.0)),\n",
        "#     transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "# ])\n",
        "\n",
        "directory_path = \"/content/drive/MyDrive/dip_final/training_dataset\"\n",
        "train_dataset = SegmentationDataset(f\"{directory_path}/image\", f\"{directory_path}/mask\", transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "directory_path = \"/content/drive/MyDrive/dip_final/testing_dataset\"\n",
        "test_dataset = SegmentationDataset(f\"{directory_path}/image\", f\"{directory_path}/mask\")\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "model = UNet().to(device)\n",
        "criterion = CombinedLoss(weight_dice=0.5, weight_ce=0.5)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-wYFbqyizg3",
        "outputId": "ac835a62-8e37-47be-af2a-7f221affe45e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Time: 5.89 Training Loss: 16.5976, Training Mean IoU: 0.2843, Validation Loss: 13.7168, Validation Mean IoU: 0.0676\n",
            "Epoch 2/100, Time: 6.23 Training Loss: 16.4250, Training Mean IoU: 0.2860, Validation Loss: 13.6904, Validation Mean IoU: 0.1489\n",
            "Epoch 3/100, Time: 5.60 Training Loss: 16.3409, Training Mean IoU: 0.3915, Validation Loss: 13.6497, Validation Mean IoU: 0.2246\n",
            "Epoch 4/100, Time: 6.20 Training Loss: 16.2108, Training Mean IoU: 0.4565, Validation Loss: 13.6404, Validation Mean IoU: 0.2173\n",
            "Epoch 5/100, Time: 6.63 Training Loss: 16.1509, Training Mean IoU: 0.4465, Validation Loss: 13.6697, Validation Mean IoU: 0.1287\n",
            "Epoch 6/100, Time: 6.23 Training Loss: 16.0816, Training Mean IoU: 0.5124, Validation Loss: 13.6635, Validation Mean IoU: 0.1403\n",
            "Epoch 7/100, Time: 5.58 Training Loss: 15.8407, Training Mean IoU: 0.5309, Validation Loss: 13.6344, Validation Mean IoU: 0.2055\n",
            "Epoch 8/100, Time: 5.45 Training Loss: 15.8094, Training Mean IoU: 0.5770, Validation Loss: 13.6324, Validation Mean IoU: 0.1921\n",
            "Epoch 9/100, Time: 6.21 Training Loss: 15.6199, Training Mean IoU: 0.5826, Validation Loss: 13.5763, Validation Mean IoU: 0.2267\n",
            "Epoch 10/100, Time: 5.50 Training Loss: 15.7004, Training Mean IoU: 0.6028, Validation Loss: 13.5753, Validation Mean IoU: 0.2325\n",
            "Epoch 11/100, Time: 6.43 Training Loss: 15.5801, Training Mean IoU: 0.6653, Validation Loss: 13.5903, Validation Mean IoU: 0.2150\n",
            "Epoch 12/100, Time: 5.38 Training Loss: 15.4455, Training Mean IoU: 0.7284, Validation Loss: 13.5889, Validation Mean IoU: 0.2328\n",
            "Epoch 13/100, Time: 5.97 Training Loss: 15.2999, Training Mean IoU: 0.7043, Validation Loss: 13.5624, Validation Mean IoU: 0.2330\n",
            "Epoch 14/100, Time: 5.87 Training Loss: 15.0682, Training Mean IoU: 0.7708, Validation Loss: 13.6005, Validation Mean IoU: 0.1951\n",
            "Epoch 15/100, Time: 5.67 Training Loss: 15.0186, Training Mean IoU: 0.7574, Validation Loss: 13.5376, Validation Mean IoU: 0.2702\n",
            "Epoch 16/100, Time: 6.13 Training Loss: 14.9931, Training Mean IoU: 0.7543, Validation Loss: 13.5637, Validation Mean IoU: 0.2651\n",
            "Epoch 17/100, Time: 5.36 Training Loss: 14.7274, Training Mean IoU: 0.7943, Validation Loss: 13.5594, Validation Mean IoU: 0.2521\n",
            "Epoch 18/100, Time: 6.10 Training Loss: 14.8760, Training Mean IoU: 0.7838, Validation Loss: 13.5691, Validation Mean IoU: 0.2607\n",
            "Epoch 19/100, Time: 5.43 Training Loss: 14.5470, Training Mean IoU: 0.8227, Validation Loss: 13.4729, Validation Mean IoU: 0.3422\n",
            "Epoch 20/100, Time: 5.81 Training Loss: 14.7356, Training Mean IoU: 0.8216, Validation Loss: 13.5992, Validation Mean IoU: 0.2164\n",
            "Epoch 21/100, Time: 5.91 Training Loss: 14.5571, Training Mean IoU: 0.8773, Validation Loss: 13.5110, Validation Mean IoU: 0.3022\n",
            "Epoch 22/100, Time: 5.64 Training Loss: 14.3275, Training Mean IoU: 0.8416, Validation Loss: 13.5421, Validation Mean IoU: 0.3015\n",
            "Epoch 23/100, Time: 6.50 Training Loss: 14.2408, Training Mean IoU: 0.8975, Validation Loss: 13.5723, Validation Mean IoU: 0.3011\n",
            "Epoch 24/100, Time: 5.43 Training Loss: 14.5166, Training Mean IoU: 0.8477, Validation Loss: 13.6272, Validation Mean IoU: 0.3689\n",
            "Epoch 25/100, Time: 6.20 Training Loss: 14.1005, Training Mean IoU: 0.9160, Validation Loss: 13.5232, Validation Mean IoU: 0.3875\n",
            "Epoch 26/100, Time: 5.56 Training Loss: 13.8449, Training Mean IoU: 0.9237, Validation Loss: 13.4398, Validation Mean IoU: 0.3975\n",
            "Epoch 27/100, Time: 5.60 Training Loss: 13.7839, Training Mean IoU: 0.9483, Validation Loss: 13.4653, Validation Mean IoU: 0.3936\n",
            "Epoch 28/100, Time: 5.93 Training Loss: 13.8062, Training Mean IoU: 0.9503, Validation Loss: 13.5030, Validation Mean IoU: 0.3802\n",
            "Epoch 29/100, Time: 5.24 Training Loss: 13.5316, Training Mean IoU: 0.9364, Validation Loss: 13.4991, Validation Mean IoU: 0.3990\n",
            "Epoch 30/100, Time: 6.45 Training Loss: 13.5212, Training Mean IoU: 0.9322, Validation Loss: 13.4941, Validation Mean IoU: 0.3999\n",
            "Epoch 31/100, Time: 5.57 Training Loss: 13.3033, Training Mean IoU: 0.9486, Validation Loss: 13.5654, Validation Mean IoU: 0.3972\n",
            "Epoch 32/100, Time: 6.01 Training Loss: 13.4919, Training Mean IoU: 0.9339, Validation Loss: 13.5231, Validation Mean IoU: 0.4027\n",
            "Epoch 33/100, Time: 5.42 Training Loss: 13.0942, Training Mean IoU: 0.9535, Validation Loss: 13.4378, Validation Mean IoU: 0.4038\n",
            "Epoch 34/100, Time: 5.17 Training Loss: 13.0744, Training Mean IoU: 0.9425, Validation Loss: 13.5040, Validation Mean IoU: 0.4029\n",
            "Epoch 35/100, Time: 6.44 Training Loss: 13.1755, Training Mean IoU: 0.9632, Validation Loss: 13.5303, Validation Mean IoU: 0.4031\n",
            "Epoch 36/100, Time: 5.30 Training Loss: 13.0684, Training Mean IoU: 0.9490, Validation Loss: 13.4788, Validation Mean IoU: 0.4034\n",
            "Epoch 37/100, Time: 6.66 Training Loss: 12.7675, Training Mean IoU: 0.9735, Validation Loss: 13.5362, Validation Mean IoU: 0.4033\n",
            "Epoch 38/100, Time: 5.51 Training Loss: 12.6799, Training Mean IoU: 0.9579, Validation Loss: 13.4820, Validation Mean IoU: 0.4045\n",
            "Epoch 39/100, Time: 5.70 Training Loss: 12.7732, Training Mean IoU: 0.9756, Validation Loss: 13.4616, Validation Mean IoU: 0.4045\n",
            "Epoch 40/100, Time: 5.95 Training Loss: 12.4130, Training Mean IoU: 0.9748, Validation Loss: 13.4790, Validation Mean IoU: 0.4047\n",
            "Epoch 41/100, Time: 5.39 Training Loss: 12.4120, Training Mean IoU: 0.9784, Validation Loss: 13.4438, Validation Mean IoU: 0.4047\n",
            "Epoch 42/100, Time: 6.39 Training Loss: 12.3536, Training Mean IoU: 0.9827, Validation Loss: 13.5261, Validation Mean IoU: 0.4047\n",
            "Epoch 43/100, Time: 5.33 Training Loss: 12.3108, Training Mean IoU: 0.9806, Validation Loss: 13.5289, Validation Mean IoU: 0.4047\n",
            "Epoch 44/100, Time: 5.88 Training Loss: 11.9774, Training Mean IoU: 0.9909, Validation Loss: 13.4644, Validation Mean IoU: 0.4047\n",
            "Epoch 45/100, Time: 5.49 Training Loss: 11.9850, Training Mean IoU: 0.9883, Validation Loss: 13.4951, Validation Mean IoU: 0.4048\n",
            "Epoch 46/100, Time: 5.46 Training Loss: 12.0533, Training Mean IoU: 0.9912, Validation Loss: 13.4784, Validation Mean IoU: 0.4047\n",
            "Epoch 47/100, Time: 6.24 Training Loss: 11.9882, Training Mean IoU: 0.9866, Validation Loss: 13.5137, Validation Mean IoU: 0.4047\n",
            "Epoch 48/100, Time: 5.55 Training Loss: 11.8858, Training Mean IoU: 0.9951, Validation Loss: 13.5567, Validation Mean IoU: 0.4047\n",
            "Epoch 49/100, Time: 6.23 Training Loss: 11.8761, Training Mean IoU: 0.9910, Validation Loss: 13.4573, Validation Mean IoU: 0.4048\n",
            "Epoch 50/100, Time: 5.55 Training Loss: 11.6437, Training Mean IoU: 0.9930, Validation Loss: 13.5098, Validation Mean IoU: 0.4048\n",
            "Epoch 51/100, Time: 5.85 Training Loss: 11.7331, Training Mean IoU: 0.9948, Validation Loss: 13.5035, Validation Mean IoU: 0.4048\n",
            "Epoch 52/100, Time: 5.78 Training Loss: 11.5026, Training Mean IoU: 0.9958, Validation Loss: 13.4734, Validation Mean IoU: 0.4048\n",
            "Epoch 53/100, Time: 5.69 Training Loss: 11.5182, Training Mean IoU: 0.9943, Validation Loss: 13.5407, Validation Mean IoU: 0.4048\n",
            "Epoch 54/100, Time: 6.34 Training Loss: 11.5316, Training Mean IoU: 0.9955, Validation Loss: 13.5238, Validation Mean IoU: 0.4048\n",
            "Epoch 55/100, Time: 5.50 Training Loss: 11.3104, Training Mean IoU: 0.9961, Validation Loss: 13.5452, Validation Mean IoU: 0.4048\n",
            "Epoch 56/100, Time: 6.54 Training Loss: 11.2935, Training Mean IoU: 0.9978, Validation Loss: 13.5324, Validation Mean IoU: 0.4048\n",
            "Epoch 57/100, Time: 5.60 Training Loss: 11.1310, Training Mean IoU: 0.9948, Validation Loss: 13.4963, Validation Mean IoU: 0.4048\n",
            "Epoch 58/100, Time: 5.99 Training Loss: 11.2821, Training Mean IoU: 0.9962, Validation Loss: 13.5610, Validation Mean IoU: 0.4048\n",
            "Epoch 59/100, Time: 5.86 Training Loss: 11.1724, Training Mean IoU: 0.9978, Validation Loss: 13.5065, Validation Mean IoU: 0.4048\n",
            "Epoch 60/100, Time: 5.26 Training Loss: 10.9602, Training Mean IoU: 0.9967, Validation Loss: 13.4868, Validation Mean IoU: 0.4048\n",
            "Epoch 61/100, Time: 6.31 Training Loss: 10.6942, Training Mean IoU: 0.9968, Validation Loss: 13.5203, Validation Mean IoU: 0.4048\n",
            "Epoch 62/100, Time: 5.33 Training Loss: 10.5474, Training Mean IoU: 0.9976, Validation Loss: 13.4999, Validation Mean IoU: 0.4048\n",
            "Epoch 63/100, Time: 6.15 Training Loss: 10.6354, Training Mean IoU: 0.9967, Validation Loss: 13.5136, Validation Mean IoU: 0.4048\n",
            "Epoch 64/100, Time: 5.20 Training Loss: 10.9131, Training Mean IoU: 0.9971, Validation Loss: 13.4855, Validation Mean IoU: 0.4048\n",
            "Epoch 65/100, Time: 5.53 Training Loss: 10.7945, Training Mean IoU: 0.9977, Validation Loss: 13.5281, Validation Mean IoU: 0.4048\n",
            "Epoch 66/100, Time: 6.37 Training Loss: 10.4779, Training Mean IoU: 0.9974, Validation Loss: 13.5252, Validation Mean IoU: 0.4048\n",
            "Epoch 67/100, Time: 5.38 Training Loss: 10.8762, Training Mean IoU: 0.9978, Validation Loss: 13.5080, Validation Mean IoU: 0.4048\n",
            "Epoch 68/100, Time: 6.25 Training Loss: 10.7651, Training Mean IoU: 0.9978, Validation Loss: 13.5262, Validation Mean IoU: 0.4048\n",
            "Epoch 69/100, Time: 5.49 Training Loss: 10.2568, Training Mean IoU: 0.9979, Validation Loss: 13.4884, Validation Mean IoU: 0.4048\n",
            "Epoch 70/100, Time: 5.84 Training Loss: 10.4501, Training Mean IoU: 0.9989, Validation Loss: 13.5101, Validation Mean IoU: 0.4048\n",
            "Epoch 71/100, Time: 5.79 Training Loss: 10.3448, Training Mean IoU: 0.9970, Validation Loss: 13.5125, Validation Mean IoU: 0.4048\n",
            "Epoch 72/100, Time: 5.51 Training Loss: 10.1354, Training Mean IoU: 0.9984, Validation Loss: 13.5329, Validation Mean IoU: 0.4048\n",
            "Epoch 73/100, Time: 6.38 Training Loss: 10.3608, Training Mean IoU: 0.9978, Validation Loss: 13.5289, Validation Mean IoU: 0.4048\n",
            "Epoch 74/100, Time: 5.33 Training Loss: 10.3576, Training Mean IoU: 0.9983, Validation Loss: 13.5301, Validation Mean IoU: 0.4048\n",
            "Epoch 75/100, Time: 6.17 Training Loss: 10.0944, Training Mean IoU: 0.9988, Validation Loss: 13.5411, Validation Mean IoU: 0.4048\n",
            "Epoch 76/100, Time: 5.52 Training Loss: 10.1006, Training Mean IoU: 0.9984, Validation Loss: 13.5298, Validation Mean IoU: 0.4048\n",
            "Epoch 77/100, Time: 5.75 Training Loss: 9.8884, Training Mean IoU: 0.9985, Validation Loss: 13.5276, Validation Mean IoU: 0.4048\n",
            "Epoch 78/100, Time: 6.00 Training Loss: 9.6328, Training Mean IoU: 0.9983, Validation Loss: 13.5658, Validation Mean IoU: 0.4048\n",
            "Epoch 79/100, Time: 5.30 Training Loss: 9.7108, Training Mean IoU: 0.9983, Validation Loss: 13.5095, Validation Mean IoU: 0.4048\n",
            "Epoch 80/100, Time: 6.34 Training Loss: 9.7099, Training Mean IoU: 0.9975, Validation Loss: 13.5229, Validation Mean IoU: 0.4048\n",
            "Epoch 81/100, Time: 5.48 Training Loss: 9.7438, Training Mean IoU: 0.9984, Validation Loss: 13.5000, Validation Mean IoU: 0.4048\n",
            "Epoch 82/100, Time: 6.17 Training Loss: 9.4117, Training Mean IoU: 0.9988, Validation Loss: 13.5491, Validation Mean IoU: 0.4048\n",
            "Epoch 83/100, Time: 5.67 Training Loss: 9.7769, Training Mean IoU: 0.9985, Validation Loss: 13.5137, Validation Mean IoU: 0.4048\n",
            "Epoch 84/100, Time: 5.51 Training Loss: 9.7429, Training Mean IoU: 0.9989, Validation Loss: 13.5191, Validation Mean IoU: 0.4048\n",
            "Epoch 85/100, Time: 6.19 Training Loss: 9.6857, Training Mean IoU: 0.9982, Validation Loss: 13.5350, Validation Mean IoU: 0.4048\n",
            "Epoch 86/100, Time: 5.32 Training Loss: 9.6119, Training Mean IoU: 0.9981, Validation Loss: 13.5064, Validation Mean IoU: 0.4048\n",
            "Epoch 87/100, Time: 6.31 Training Loss: 9.0875, Training Mean IoU: 0.9985, Validation Loss: 13.5280, Validation Mean IoU: 0.4048\n",
            "Epoch 88/100, Time: 5.38 Training Loss: 9.6145, Training Mean IoU: 0.9982, Validation Loss: 13.5545, Validation Mean IoU: 0.4048\n",
            "Epoch 89/100, Time: 5.83 Training Loss: 9.7853, Training Mean IoU: 0.9987, Validation Loss: 13.5979, Validation Mean IoU: 0.4048\n",
            "Epoch 90/100, Time: 5.87 Training Loss: 9.3837, Training Mean IoU: 0.9979, Validation Loss: 13.5351, Validation Mean IoU: 0.4048\n",
            "Epoch 91/100, Time: 5.44 Training Loss: 9.2374, Training Mean IoU: 0.9986, Validation Loss: 13.5379, Validation Mean IoU: 0.4048\n",
            "Epoch 92/100, Time: 6.44 Training Loss: 8.9262, Training Mean IoU: 0.9986, Validation Loss: 13.5205, Validation Mean IoU: 0.4048\n",
            "Epoch 93/100, Time: 5.50 Training Loss: 9.2537, Training Mean IoU: 0.9977, Validation Loss: 13.5606, Validation Mean IoU: 0.4048\n",
            "Epoch 94/100, Time: 6.30 Training Loss: 9.1377, Training Mean IoU: 0.9967, Validation Loss: 13.5633, Validation Mean IoU: 0.4048\n",
            "Epoch 95/100, Time: 5.62 Training Loss: 9.4374, Training Mean IoU: 0.9985, Validation Loss: 13.5700, Validation Mean IoU: 0.4048\n",
            "Epoch 96/100, Time: 5.47 Training Loss: 8.9934, Training Mean IoU: 0.9984, Validation Loss: 13.5386, Validation Mean IoU: 0.4048\n",
            "Epoch 97/100, Time: 5.89 Training Loss: 9.3220, Training Mean IoU: 0.9981, Validation Loss: 13.5355, Validation Mean IoU: 0.4048\n",
            "Epoch 98/100, Time: 5.40 Training Loss: 8.7660, Training Mean IoU: 0.9980, Validation Loss: 13.5410, Validation Mean IoU: 0.4048\n",
            "Epoch 99/100, Time: 6.27 Training Loss: 8.6722, Training Mean IoU: 0.9975, Validation Loss: 13.5412, Validation Mean IoU: 0.4048\n",
            "Epoch 100/100, Time: 5.44 Training Loss: 8.6888, Training Mean IoU: 0.9973, Validation Loss: 13.5804, Validation Mean IoU: 0.4048\n",
            "Training Complete!\n",
            "Best Mean IoU: 0.4048, at epoch 50\n"
          ]
        }
      ],
      "source": [
        "phases = [\"train\", \"valid\"]\n",
        "data_loader = {\"train\": train_dataloader, \"valid\": test_dataloader}\n",
        "best_mean_iou = 0\n",
        "best_epoch = 0\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "    for phase in phases:\n",
        "        if phase == \"train\":\n",
        "            model.train()\n",
        "            train_loss = 0\n",
        "            train_iou_scores = []\n",
        "        elif phase == \"valid\":\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            val_iou_scores = []\n",
        "\n",
        "        for images, masks in data_loader[phase]:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "            if phase == \"train\":\n",
        "                outputs = model(images)\n",
        "\n",
        "                masks = masks.unsqueeze(1)\n",
        "                loss = criterion(outputs, masks)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "\n",
        "                iou = calculate_iou(outputs, masks)\n",
        "                train_iou_scores.append(iou)\n",
        "            elif phase == \"valid\":\n",
        "                with torch.no_grad():\n",
        "                    images = images.permute(0,3,1,2)\n",
        "                    masks = masks.unsqueeze(1)\n",
        "                    outputs = model(images)\n",
        "\n",
        "                    loss = criterion(outputs, masks)\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "\n",
        "                    iou = calculate_iou(outputs, masks)\n",
        "                    val_iou_scores.append(iou)\n",
        "\n",
        "    end_time = time.time()\n",
        "    train_mean_iou = sum(train_iou_scores) / len(train_iou_scores)\n",
        "    val_mean_iou = sum(val_iou_scores) / len(val_iou_scores)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Time: {end_time - start_time:.2f} Training Loss: {train_loss:.4f}, Training Mean IoU: {train_mean_iou:.4f}, Validation Loss: {val_loss:.4f}, Validation Mean IoU: {val_mean_iou:.4f}\")\n",
        "\n",
        "    if val_mean_iou > best_mean_iou:\n",
        "        best_mean_iou = val_mean_iou\n",
        "        best_epoch = epoch\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/dip_final/best_epoch.pth')\n",
        "\n",
        "print(\"Training Complete!\")\n",
        "print(f\"Best Mean IoU: {best_mean_iou:.4f}, at epoch {best_epoch}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "T-NKZnuaizg4",
        "outputId": "f45269fe-7052-4184-c5ab-7e625d051599"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [8, 3, 3, 3], expected input[1, 1152, 1536, 3] to have 3 channels, but got 1152 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b1a26c4fc3fd>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0miou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-788bf47a1f39>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0menc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0menc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0menc3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [8, 3, 3, 3], expected input[1, 1152, 1536, 3] to have 3 channels, but got 1152 channels instead"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/dip_final/best_epoch.pth', weights_only=True))\n",
        "model.eval()\n",
        "iou_scores = []\n",
        "output_dir = \"/content/drive/MyDrive/dip_final/output\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, (images, masks) in enumerate(test_dataloader):\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        iou = calculate_iou(outputs, masks)\n",
        "\n",
        "        iou_scores.append(iou)\n",
        "\n",
        "        output_image_path = os.path.join(output_dir, f\"output_{idx + 1}.png\")\n",
        "\n",
        "        output_and_mask = torch.cat((masks, outputs), dim=3).squeeze().cpu().numpy()\n",
        "        output_and_mask_image = tensor_to_required_image(output_and_mask, f\"{directory_path}/mask\", idx + 1)\n",
        "        output_and_mask_image.save(output_image_path)\n",
        "\n",
        "        print(f\"Saved output and mask for image {idx + 1}. IoU: {iou:.4f}\")\n",
        "\n",
        "mean_iou = sum(iou_scores) / len(iou_scores)\n",
        "print(f\"Mean IoU: {mean_iou:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}